---
title: "QTW FINAL CASE STUDY SUMMER 2020"
output: html_notebook
---
```{r}
#data manipulation
library(tidyverse)
library(dplyr)
#visualization
library(ggplot2)
library(skimr)
library(corrplot)
#prediction
library(RSNNS) 
```
data from - https://smu.box.com/s/k9x192jxm39enjw2wx8ouw2kopx33l32
classify column 'y' using features x0-x49
minimize cost on a theorhetical unknown dataset, where
false positive = -10$
false negative = -500$
true positive/negative = -0$

include- 
confusion plot 
with costs average/predicted as a model metric

```{r}
#file_name = file.choose()
#data_raw = read.csv(file_name)
data_raw = read.csv('D:/SMU/DS 7333 Quantify The World/qtw_final_project.csv')
```

cleaning section and eda

```{r}
#eda with skimr
skim(data_raw) %>% dplyr::select(skim_type, skim_variable, n_missing)
skim(data_raw) %>% dplyr::select(skim_type, skim_variable, numeric.mean)
```
most columns look like they are missing a few, less than triple digits. Likely not significant next to the 160K total rows
```{r}
#remove rows with na
data_v1 <- data_raw[complete.cases(data_raw), ]
dim(data_v1)
```
from 160,000 to 158,534, removing all rows with NA loses 1,500 ish rows, or 0.9% of data
```{r}
#col 37 is dollar amounts stored as characters, need to convert
data_v1$x37 <- as.numeric(substr(data_v1$x37, 2, nchar(data_v1$x37))) #index string with substring to cut out the dollar sign and convert to numeric 
#same for col 32
data_v1$x32 <- as.numeric(substr(data_v1$x32, 1, nchar(data_v1$x32)-1)) #same thing
```
ok, now we have numeric values for x37 instead of characters, run na removal again
```{r}
data_v1 <- data_v1[complete.cases(data_v1), ]
dim(data_v1)
```
trims off another 70 rows, negligible (probably)
```{r}
# #isolate numeric columns only
# numeric_only <- data_v1[, unlist(lapply(data_v1, is.numeric))] 
# #corrplot
# cor1 <- cor(numeric_only)
# corrplot(cor1, method = 'circle')
# ggsave('corplot1.png', device = 'png', plot = last_plot(), dpi = 300, width = 10, height = 10, units = 'in')
# #saves to wherever getwd() is pointing
```
A bit had to interpret, but what we really care about is column y, which doesn't have any outstanding correlations. some minor positive corelations with 20 and 23, and minor negative with 40 and 49. (easier to read in separate window)

also note that rows 2/6 and 38/41 are closely correlated, may be able to eliminate one

```{r}
#looking at number of categorical variables in each non-numeric column 
non_numeric_only <- data_v1[, !unlist(lapply(data_v1, is.numeric))] 

for(i in 1:length(non_numeric_only)){
  print(table(non_numeric_only[, i]))
}
```
not too many labels to one hot encode
```{r}
#assign numeric values to each reigon, asia, america, 'euorpe'
temp_labels <- unique(non_numeric_only$x24)
tc = non_numeric_only$x24 #target column
for(i in 1:length(tc)){
  if(tc[i] == temp_labels[1]){
    encoded_value <- 1
  }
  if(tc[i] == temp_labels[2]){
    encoded_value <- 2
  }
  if(tc[i] == temp_labels[3]){
    encoded_value <- 3
  }
  if(tc[i] == temp_labels[4]){
    encoded_value <- 4
  }
  else{
    #encoded_value <- NA
  }
  tc[i] <- encoded_value
}
temp_labels
table(tc)
reigon_encoded <- as.numeric(tc) #store for later integration
```
```{r}
#monthly encoding
temp_labels <- unique(non_numeric_only$x29)
tc = non_numeric_only$x29 #target column
for(i in 1:length(tc)){
  if(tc[i] == 'January'){
    encoded_value <- 1}
  if(tc[i] == 'Feb'){
    encoded_value <- 2}
  if(tc[i] == 'Mar'){
    encoded_value <- 3}
  if(tc[i] == "Apr"){
    encoded_value <- 4}
  if(tc[i] == "May"){
    encoded_value <- 5}
  if(tc[i] == "Jun"){
    encoded_value <- 6}
  if(tc[i] == "July"){
    encoded_value <- 7}
  if(tc[i] == "Aug"){
    encoded_value <- 8}
  if(tc[i] == "sept."){
    encoded_value <- 9}
  if(tc[i] == "Oct"){
    encoded_value <- 10}
  if(tc[i] == "Nov"){
    encoded_value <- 11}
  if(tc[i] == "Dev"){
    encoded_value <- 12}
  if(tc[i] == ""){
    encoded_value <- 13}

  tc[i] <- encoded_value
}
temp_labels
table((non_numeric_only$x29))
table(tc)
month_encoded <-as.numeric(tc) #store for later integration

```
ok, sorted months match up 

```{r}
#day of week encoding
temp_labels <- unique(non_numeric_only$x30)
tc = non_numeric_only$x30 #target column
for(i in 1:length(tc)){
  if(tc[i] == 'monday'){
    encoded_value <- 1}
  if(tc[i] == 'tuesday'){
    encoded_value <- 2}
  if(tc[i] == 'wednesday'){
    encoded_value <- 3}
  if(tc[i] == 'thurday'){
    encoded_value <- 4}
  if(tc[i] == 'friday'){
    encoded_value <- 5}
  if(tc[i] == ''){
    encoded_value <- 6}
  tc[i] <- encoded_value
}
temp_labels
table((non_numeric_only$x30))
table(tc)
weekday_encoded <-as.numeric(tc) #store for later integration
```
'thurday' <-----
anyways, same matchups, looks correct

now integrate these values back into another version of the data in order to do correlation analysis on all numerics
```{r}
data_v2 <- data_v1
data_v2$x24 <- reigon_encoded
data_v2$x29 <- month_encoded
data_v2$x30 <- weekday_encoded

numeric_only <- data_v2[, unlist(lapply(data_v2, is.numeric))] 
cor2 <- cor(numeric_only)
corrplot(cor2, method = 'circle')
```
hm ok not much of a difference, 24, 29, and 30 don't have any strong correlation with y, but might be useful to have everything numeric anyways

NN classification test 1
```{r}
#stuttgart neural network simulator test
#where size = units in hidden layer

inputs_v3 <- data_v2[, -data_v2$y]
target_v3 <- data_v2$y
data_v4 <- splitForTrainingAndTest(inputs_v3, target_v3, ratio = 0.3)

model1 <- mlp(data_v4$inputsTrain, data_v4$targetsTrain, size = 5, learnFuncParams = c(0.1), maxit = 50, inputsTest = data_v4$inputsTest, targetsTest = data_v4$targetsTest)
```

```{r}
summary(model1)
model1
extractNetInfo(model1)

confusionMatrix(data_v4$targetsTrain, fitted.values(model1))
#confusionMatrix(data_v4$targetsTest, predictions)
```

hmm outputs aren't coming out as 1/0, maybe need to switch to categorical?? 






















