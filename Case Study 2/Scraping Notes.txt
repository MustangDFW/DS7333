Notes on scraping process/Data Preparation
The per year results for the race does not have standardized formats, 2008 and 2007 have completely different row titles and orders. Initial attempts to parse this data from an XML format in R with rvest xml2 was arduous and time consuming, as each new format required a different set of rules to govern the separation of characters into the appropriate strings and columns. The unstandardized nature of each year's results page also meant that XML structure locations for tables and rows changed each year. 
The problem of different race formats was solved by looking at the paginated results and switching to python, which has a more novice friendly package, BeautifulSoup. The searchable results page effectively contained all the results from all years, where the columns and formats are all standardized. By iterating on the page numbers of the results for each race, BeautifulSoup can pull down the table from each page of the race results with consistent columns and formats per column. Because all the paginated results are accessed through the same format URL, we can iterate through the page number and year to access all the results in this category from 1999 to 2012. 

http://www.cballtimeresults.org/performances?division=Overall+Women&page={PAGE_NUMBER}&section=10M&sex=W&utf8=%E2%9C%93&year={YEAR_NUMBER}

The {} sections were iterated with simple counters for the ranges of number of pages per year, and years from 1999 to 2012 respectively. Using the XML tags in hierarchical order, locations for desired data were located using (th) for table headers, (tr) for rows, and (td) for the cells within that row. Calling for the (td) in each page results in a single dimensional array that contains every cell in the table. In the interest of speed, each row was populated via loop for the desired 9 cells per row. Iterating with counters allows the results of each row to be stored in a single array per year. The array was then written to a csv file for easy retrieval without running all the functions again. All these tasks were wrapped into a single function and called once for each year for bug testing, though in the future iteration should be possible over the years as well. 
The resulting 13 CSV files were then imported into R to take advantage of ggplot2, checked for inconsistencies (only found that the state name was generating an extra column next to hometown for some of the years, this was dropped as the state name of the runners was not pertinent information for the scope of this case study), converted into dataframes, vertically merged with rbind, then exported again as the final csv with all the race results data from 1999 to 2012. The final csv contained all female runner's results from races in years 1999 - 2012, and served as the baseline for further analysis. 
