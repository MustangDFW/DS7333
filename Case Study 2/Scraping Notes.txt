Notes on scraping process/Data Preparation
The per year results for the race does not have standardized formats
2008 and 2007 have completely different row titles and orders. Initial attempts to parse this data from an XML format in R was arduous and time consuming, as each new format required a different set of rules to govern the separation of characters into the appropriate strings and columns. 
The problem of different race formats was solved by looking at the paginated results, where the columns and formats are all standardized. By iterating on the page numbers of the results for each race, BeautifulSoup can pull down the table from each page of the race results with consistent columns and formats per column. Because all the paginated results are accessed through the same format URL, we can iterate through the page number and year to access all the results in this category from 1999 to 2012. 

http://www.cballtimeresults.org/performances?division=Overall+Women&page={1}&section=10M&sex=W&utf8=%E2%9C%93&year={1999}

The (bold/highlighted/format stuff in the {} however to make them stand out) sections were iterated with simple counters for the ranges of number of pages per year, and years from 1999 to 2012 respectively. Using the (XML? tags?) in hierarchical order (th) for table headers, (tr) for rows, and (td) for the cells within that row. Calling for the (td) in each page results in a single dimensional array that contains every cell in the table. (there are probably better ways to do this, but in the interest of time) each row was populated via loop for the desired 9 cells per row. Iterating with counters allows the results of each row to be stored in a single array per year. The array was then written to a csv file for easy retrieval without running all the functions again. All these (processes? Actions? tasks?) were wrapped into a single function and called once for each year for bug testing, though in the future iteration should be possible over the years as well. 
The resulting 13 CSV files were then imported into R (because I like ggplot), checked for inconsistencies (only found that the state name was generating an extra column next to hometown for some of the years, this was dropped as the state name of the runners was not pertinent information for the scope of this case study), converted into dataframes, vertically merged with rbind, then exported again as the final csv with all the race results data from 1999 to 2012.
