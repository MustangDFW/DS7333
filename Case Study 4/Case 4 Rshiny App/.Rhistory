}
return(cast_frame)
}
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
print(paste(length(before_block), length(after_block)))
}
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
print(length(c(before_block, fcasts[i, ], after_block))
#cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
print(length(c(before_block, fcasts[i, ], after_block))
#cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
cast_frame = 0
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
print(length(c(before_block, fcasts[i, ], after_block)))
#cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
fcasts[9]
fcasts[9, ]
#function to space out forecasts with NAs for plotting
fspacer <- function(fcasts){
cast_frame = 0
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
print(length(c(before_block, fcasts[i, ], after_block)))
#cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
return(cast_frame)
}
f_spaced <- fspacer(fcastHolder)
fframe <- list()
for(i in 1:n_windows){
#name = paste0('df', i)
lname = paste0('w', i)
#assign(name, data.frame(date = ttime, pred = f_spaced[i, ]))
tmp <- data.frame(date = ttime, pred = f_spaced[i, ])
fframe[[lname]] <- tmp
}
f_df <- cbind(cat= rep(names(fframe), sapply(fframe, NROW)), do.call(rbind, fframe)) #arrange data with category by prediction window
o_df <- data.frame(cat = rep('original', length(tdata)), date = ttime, pred = tdata) #add actual data as rbind
f_df <- rbind(f_df, o_df)
ggplot(f_df, aes(date,pred, color= cat)) + geom_line() +
#geom_line(aes(ttime, y = tdata)) +
ggtitle("Total Influenza Test Cases: India", subtitle = '2016 - 2019')
#function to space out forecasts with NAs for plotting
fspacer <- function(fcasts){
cast_frame = 0
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
print(length(c(before_block, fcasts[i, ], after_block)))
#cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
return(cast_frame)
}
f_spaced <- fspacer(fcastHolder)
#function to space out forecasts with NAs for plotting
fspacer <- function(fcasts){
cast_frame = 0
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
#print(length(c(before_block, fcasts[i, ], after_block)))
cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
return(cast_frame)
}
f_spaced <- fspacer(fcastHolder)
warnings()
f_spaced
View(f_spaced)
for(i in 1:n_windows){print(trainingSize+(step_size*(i-1)))}
i
length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon
9+4+184
#function to space out forecasts with NAs for plotting
fspacer <- function(fcasts){
cast_frame = 0
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
#print(length(c(before_block, fcasts[i, ], after_block)))
cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
return(cast_frame)
}
f_spaced <- fspacer(fcastHolder)
f_spaced <- fspacer(fcastHolder)
fframe <- list()
for(i in 1:n_windows){
#name = paste0('df', i)
lname = paste0('w', i)
#assign(name, data.frame(date = ttime, pred = f_spaced[i, ]))
tmp <- data.frame(date = ttime, pred = f_spaced[i, ])
fframe[[lname]] <- tmp
}
f_df <- cbind(cat= rep(names(fframe), sapply(fframe, NROW)), do.call(rbind, fframe)) #arrange data with category by prediction window
o_df <- data.frame(cat = rep('original', length(tdata)), date = ttime, pred = tdata) #add actual data as rbind
f_df <- rbind(f_df, o_df)
ggplot(f_df, aes(date,pred, color= cat)) + geom_line() +
#geom_line(aes(ttime, y = tdata)) +
ggtitle("Total Influenza Test Cases: India", subtitle = '2016 - 2019')
?ggitle
?ggtitle
#create categorical dataframe to store windowed predictions
fframe <- list()
for(i in 1:n_windows){
#name = paste0('df', i)
lname = paste0('w', i)
#assign(name, data.frame(date = ttime, pred = f_spaced[i, ]))
tmp <- data.frame(date = ttime, pred = f_spaced[i, ])
fframe[[lname]] <- tmp
}
f_df <- cbind(cat= rep(names(fframe), sapply(fframe, NROW)), do.call(rbind, fframe)) #arrange data with category by prediction window
o_df <- data.frame(cat = rep('original', length(tdata)), date = ttime, pred = tdata) #add actual data as rbind
f_df <- rbind(f_df, o_df)
ggplot(f_df, aes(date,pred, color= cat)) + geom_line() +
ggtitle("Total Influenza Test Cases: India 2016 - 2019", subtitle = paste("Mean ASE across [", n_windows, '] moving windows: ', WindowedASE))
#analysis packages
library(tswge)
library(changepoint)
library(tseries)
library(DataExplorer)
library(nnfor)
#data manipulation
library(dplyr)
library(lubridate)
library(tibbletime)
#visualization
library(ggplot2)
library(cowplot)
library(kableExtra)
#data source
library(cdcfluview)
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport(SE_Asia_1995-2019).csv')
S_Asia <- raw_data[which(raw_data$FLUREGION == 'Southern Asia'), ] #select rows from SE asia
tlist <- S_Asia[complete.cases(S_Asia$ALL_INF), ] #select only rows that aren't missing data in the all_inf column
t_ind <- tlist[which(tlist['ï..Country'] == 'India'), ]
t_ind <- t_ind[which(t_ind$Year == 2017| t_ind$Year == 2018 | t_ind$Year == 2019), ] #select 3 years
ttime = t_ind$SDATE %>% as.Date("%m/%d/%Y") #store the timeline as date object vector
#it looks like all the weeks fall on the same SDATE's, so it should be safe to use the same date vector for different countries.
ggplot(t_ind) +
geom_line(aes(x = ttime, y = ALL_INF, col = 'Total Influenza Cases'))+
#geom_line(aes(x = ttime, y = AH1, col = 'AH1'))+
#geom_line(aes(x = ttime, y = AH1N12009, col = '2009 Swine Flu'))+
#geom_line(aes(x = ttime, y = AH3, col = 'AH3'))+
#geom_line(aes(x = ttime, y = AH5, col = 'AH5'))+
#geom_line(aes(x = ttime, y = ANOTSUBTYPED, col = 'Untyped Inf A'))+
geom_line(aes(x = ttime, y = INF_A, col = 'total type A'))+
#geom_line(aes(x = ttime, y = BYAMAGATA, col = 'Yamagata STRAIN B'))+
#geom_line(aes(x = ttime, y = BVICTORIA, col = 'Victoria Strain B'))+
#geom_line(aes(x = ttime, y = BNOTDETERMINED, col = 'Untyped Inf B'))+
geom_line(aes(x = ttime, y = INF_B, col = 'total type B')) +
scale_y_continuous()
tdata = t_ind$ALL_INF
#wrap objects in invisible() to hide the long console output and leave only the graph
invisible(plotts.sample.wge(tdata))
#stationairity
adf.test(tdata)
pacf(tdata)
#changepoint
par(mfrow = c(2,1))
v2 <- tdata
v2.pelt <- cpt.meanvar(v2, test.stat = 'Poisson', method = "PELT")
plot(v2.pelt, main = 'PELT changes in variance')
cpts.ts(v2.pelt)
v2.bs <- cpt.meanvar(v2, test.stat = 'Poisson', method = 'BinSeg')
plot(v2.bs, cpt.width = 3, main = 'BinSeg changes in Mean Variance')
cpts.ts(v2.bs)
#take first difference #jk didn't need this
#d1 = artrans.wge(tdata, phi.tr = 1)
#adf.test(d1)
#model fitting with tdata
pspan = 0:10 #range of values to look for possible p and q coefficients for AR and MA
qspan = 0:8
difference = 0
aic_results <- aic5.wge(tdata, p = pspan, q = qspan)
bic_results <- aic5.wge(tdata, p = pspan, q = qspan, type = 'bic')
aic_results
bic_results
m1 = est.arma.wge(tdata, p = aic_results[1, 1], q = aic_results[1, 2], factor = TRUE) #feed top AIC or BIC into arma estimation to generate coefficients
m1$phi
m1$theta
#simple single forecast and test
weeks_compare = 24 #how many weeks to reserve for testing : 6months
f1 <- tdata[1:(length(tdata)-weeks_compare)] %>% fore.aruma.wge(phi = m1$phi, theta = m1$theta, d = 0, n.ahead = weeks_compare)
mse <- mean((tdata[((length(tdata)-weeks_compare)+1):(length(tdata))] - f1$f)^2)
paste('Mean Squared Error: ', mse)
#additional metrics
a_metrics <- accuracy(f1$f, tdata[((length(tdata)-weeks_compare)+1):(length(tdata))] )
#change x and y line names to match whatever dataframe you've stored the time series in
timeFrame <- data.frame(date = ttime, inf_cases = tdata)
g3 <- ggplot(timeFrame)+
geom_line(aes(x = date, y = tdata, color = 'black'), size = 0.5)+
geom_line(aes(x = date, y = c(rep(NA, length(tdata)-weeks_compare), f1$f), color = 'red'), size= 1) +
scale_color_discrete(name = "total_patients", labels = c('actual', 'predicted')) +
ggtitle(paste('ARIMA (',aic_results[1, 1],',',aic_results[1, 2],',',difference,')', 'Forecast of ', weeks_compare, ' weeks'), subtitle = paste('Mean Squared Error = ', mse))
g3
#rolling window ase: apply model predictions to small segments of the given data and aggregate metrics
trainingSize = 24
horizon = 4
step_size = 8
n_windows = nrow = round(length(tdata)/(trainingSize + horizon)) #number of whole windows of training size + horizon that will fit into the given data
ASEHolder = numeric()
fcastHolder = matrix(nrow = n_windows, ncol = horizon) #create matrix that has the number of rows and columns corresponding to number of windows and length of forecast interval
fUpperHolder = matrix(nrow = n_windows, ncol = horizon) #same for upper and lower intervals
fLowerHolder = matrix(nrow = n_windows, ncol = horizon)
phis = m1$phi
thetas = m1$theta
s = 0
d = 0
for( i in 1:n_windows) #how many "windows" can fit into the total length of time, rounding down
{
forecasts = fore.aruma.wge(tdata[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = s, d = d,n.ahead = horizon)
ASE = mean((tdata[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
ASEHolder[i] = ASE
fcastHolder[i, ] <- forecasts$f
fUpperHolder[i, ] <- forecasts$ul
fLowerHolder[i, ] <- forecasts$ll
}
ASEHolder
WindowedASE = mean(ASEHolder)
hist(ASEHolder, main = paste("Mean ASE across [", n_windows, '] moving windows: ', WindowedASE))
summary(ASEHolder)
print(paste("Mean ASE across ", n_windows, ' moving windows: ', WindowedASE))
#updated with step size,how much the "window" moves per interval
#rolling window ase: apply model predictions to small segments of the given data and aggregate metrics
trainingSize = 24
horizon = 4
step_size = 8
n_windows = round((length(tdata)-(trainingSize + horizon))/step_size) #number of whole windows of training size + horizon that will fit into the given data, divided by step size
ASEHolder = numeric()
fcastHolder = matrix(nrow = n_windows, ncol = horizon) #create matrix that has the number of rows and columns corresponding to number of windows and length of forecast interval
fUpperHolder = matrix(nrow = n_windows, ncol = horizon) #same for upper and lower intervals
fLowerHolder = matrix(nrow = n_windows, ncol = horizon)
phis = m1$phi
thetas = m1$theta
s = 0
d = 0
for( i in 1:n_windows) #how many "windows" can fit into the total length of time, rounding down
{
t_start = 1+(step_size*(i-1)) #starting point for each window's training data
t_end = trainingSize + (step_size*(i-1)) #endpoint
forecasts = fore.aruma.wge(tdata[t_start:t_end],phi = phis, theta = thetas, s = s, d = d, n.ahead = horizon)
ASE = mean((tdata[(t_end + 1):(t_end+horizon)] - forecasts$f)^2)
ASEHolder[i] = ASE
fcastHolder[i, ] <- forecasts$f
fUpperHolder[i, ] <- forecasts$ul
fLowerHolder[i, ] <- forecasts$ll
#print(paste(t_start, t_end))
}
ASEHolder
WindowedASE = mean(ASEHolder)
hist(ASEHolder, main = paste("Mean ASE across [", n_windows, '] moving windows: ', WindowedASE))
summary(ASEHolder)
print(paste("Mean ASE across ", n_windows, ' moving windows: ', WindowedASE))
#function to space out forecasts with NAs for plotting
fspacer <- function(fcasts){
cast_frame = 0
cast_frame = matrix(nrow = n_windows, ncol = length(tdata)) #empty matrix to hold spaced out forecasts
for(i in 1:n_windows)
{
#print(i)
before_block <- rep(NA, (trainingSize + (step_size*(i-1))))
after_block <- c(rep(NA, (length(tdata) - length(c(rep(NA, (trainingSize + step_size*(i-1))))) - horizon)))
#print(paste(length(before_block), length(after_block)))
#print(length(c(before_block, fcasts[i, ], after_block)))
cast_frame[i, ] <- c(before_block, fcasts[i, ], after_block)
#print(cast_frame[i, ])
}
return(cast_frame)
}
f_spaced <- fspacer(fcastHolder)
#create categorical dataframe to store windowed predictions
fframe <- list()
for(i in 1:n_windows){
#name = paste0('df', i)
lname = paste0('w', i)
#assign(name, data.frame(date = ttime, pred = f_spaced[i, ]))
tmp <- data.frame(date = ttime, pred = f_spaced[i, ])
fframe[[lname]] <- tmp
}
f_df <- cbind(cat= rep(names(fframe), sapply(fframe, NROW)), do.call(rbind, fframe)) #arrange data with category by prediction window
o_df <- data.frame(cat = rep('original', length(tdata)), date = ttime, pred = tdata) #add actual data as rbind
f_df <- rbind(f_df, o_df)
ggplot(f_df, aes(date,pred, color= cat)) + geom_line() +
ggtitle("Total Influenza Test Cases: India 2017 - 2019", subtitle = paste("Mean ASE across [", n_windows, '] moving windows: ', WindowedASE))
library(shiny)
install.packages('shiny')
install.packages("shiny")
library(shiny)
library(shiny)
install.packages("shiny")
install.packages("shiny")
install.packages("shiny")
install.packages("shiny")
install.packages('shiny')
library(shiny); runApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
runApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
runApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
runApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
runApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
runApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='seashell-scientist',
token='5A82FEA71925DEED0CFDDEC96DCFF7DB',
secret='XaybAUJF9JzxitfQPktFyc+s8/gPMr/naDsto8RE')
library(rsconnect)
rsconnect::deplyAp('D:\SMU\DS 7333 Quantify The World\shinytest.r')
rsconnect::deplyAp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
rsconnect::deployApp('D:/SMU/DS 7333 Quantify The World/shinytest.r')
rsconnect::deployApp('D:/SMU/DS 7333 Quantify The World/app.R')
rsconnect::deployApp()
runApp('D:/SMU/DS 7333 Quantify The World')
install.packages("factoextra")
#analysis packages
library(tswge)
library(changepoint)
library(tseries)
library(DataExplorer)
library(nnfor)
#data manipulation
library(dplyr)
library(lubridate)
library(tibbletime)
#visualization
library(ggplot2)
library(cowplot)
library(kableExtra)
#data source
library(cdcfluview)
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport(SE_Asia_1995-2019).csv')
shiny::runApp('D:/SMU/DS 7333 Quantify The World')
runApp('D:/SMU/DS 7333 Quantify The World')
shiny::runApp('D:/SMU/DS 7333 Quantify The World')
runApp('D:/SMU/DS 7333 Quantify The World')
e$x
runApp('D:/SMU/DS 7333 Quantify The World')
shiny::runApp('D:/SMU/DS 7333 Quantify The World')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/testapp2')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/testapp2')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/testapp2')
install.packages("BiocManager")
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/testapp2')
install.packages("BiocManager")
install.packages("BiocManager")
library(shiny); runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1/c4_ntest1.R')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1/c4_ntest1.R')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1/c4_ntest1.R')
bioc
bioc <- local({
env <- new.env()
on.exit(rm(env))
evalq(source("http://bioconductor.org/biocLite.R", local = TRUE), env)
biocinstallRepos()
})
BiocManager::repositories()
library(BiocManager)
options(repos = BiocManageer::repositories())
options(repos = BiocManager::repositories())
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
getOption("repos")
BiocManager::install(version = '3.11')
shiny::runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
raw_data  <- read.csv('FluNetInteractiveReport(SE_Asia_1995-2019).csv')
S_Asia <- raw_data[which(raw_data$FLUREGION == 'Southern Asia'), ]
raw_data  <- read.csv('FluNetInteractiveReport(SE_Asia_1995-2019).csv')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
range_data = vector()
for(j in year_range[1:3){
range_data <- rbind(range_data, t_ind[which(t_ind$Year == j), ])
}
tdata <- (range_data$ALL_INF) #set primary ts to all influenza cases
ttime <- (range_data$SDATE) %>% as.Date("%m/%d/%Y") %>% sort()
range_data = vector()
for(j in year_range[1:2]){
range_data <- rbind(range_data, t_ind[which(t_ind$Year == j), ])
}
tdata <- (range_data$ALL_INF) #set primary ts to all influenza cases
ttime <- (range_data$SDATE) %>% as.Date("%m/%d/%Y") %>% sort()
}
range_data = vector()
for(j in year_range[1:2]){
range_data <- rbind(range_data, t_ind[which(t_ind$Year == j), ])
}
tdata <- (range_data$ALL_INF) #set primary ts to all influenza cases
ttime <- (range_data$SDATE) %>% as.Date("%m/%d/%Y") %>% sort()
raw_data  <- read.csv('FluNetInteractiveReport_SE_Asia_1995-2019.csv')
S_Asia <- raw_data[which(raw_data$FLUREGION == 'Southern Asia'), ]
t_ind <- S_Asia[which(S_Asia[1] == 'India'), ]
t_ind$ALL_INF[is.na(t_ind$ALL_INF)] <- 0
raw_data  <- read.csv('FluNetInteractiveReport_SE_Asia_1995-2019.csv')
load("D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/FluNetInteractiveReport_SE_Asia_1995-2019.csv")
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
#analysis packages
library(tswge)
library(changepoint)
library(tseries)
library(DataExplorer)
library(nnfor)
#data manipulation
library(dplyr)
library(lubridate)
library(tibbletime)
#visualization
library(ggplot2)
library(cowplot)
library(kableExtra)
#data source
library(cdcfluview)
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
S_Asia <- raw_data[which(raw_data$FLUREGION == 'Southern Asia'), ]
t_ind <- S_Asia[which(S_Asia[1] == 'India'), ]
t_ind$ALL_INF[is.na(t_ind$ALL_INF)] <- 0
year_range = 1995:2019 #call with year_range[1], ect
ange_data = vector()
for(j in year_range[22:25]){
range_data <- rbind(range_data, t_ind[which(t_ind$Year == j), ])
}
range_data = vector()
for(j in year_range[22:25]){
range_data <- rbind(range_data, t_ind[which(t_ind$Year == j), ])
}
View(range_data)
t_ind[which(t_ind$Year == 1994), ]
t_ind[which(t_ind$Year == 1996), ]
runApp('D:/SMU/DS 7333 Quantify The World/Case 4 rshiny app/ntest1')
shiny::runApp()
runApp()
library("shiny")
library("ggplot2")
library("tidyverse")
library("dplyr")
#library("tswge") #so this is what doesn't play nice with rshiny deployment? something to do with bioconductor repo availability???
library("cdcfluview")
raw_data  <- read.csv('D:/SMU/DS 7333 Quantify The World/FluNetInteractiveReport_SE_Asia_1995-2019.csv')
S_Asia <- raw_data[which(raw_data$FLUREGION == 'Southern Asia'), ] #select rows from SE asia
tlist <- S_Asia[complete.cases(S_Asia$ALL_INF), ] #select only rows that aren't missing data in the all_inf column
t_ind <- tlist[which(tlist['ï..Country'] == 'India'), ]
t_ind <- t_ind[which(t_ind$Year == 2017| t_ind$Year == 2018 | t_ind$Year == 2019), ] #select 3 years
ttime = t_ind$SDATE %>% as.Date("%m/%d/%Y")
AIC(t_ind$ALL_INF)
?AIC
model = arima(t_ind$ALL_INF, order = c(4, 5, 0), method = "ML")
AIC(model)
shiny::runApp()
runApp('D:/SMU/Github Projects/DS7333/Case Study 4/Case 4 Rshiny App')
